{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295e71ff",
   "metadata": {},
   "source": [
    "# Versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beaafc0",
   "metadata": {},
   "source": [
    "## Original TikTok version d250810.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaddf85",
   "metadata": {},
   "source": [
    "- Ref. '<https://www.tiktok.com/@pyatsplusom/video/7535003211887889695>'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e314390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ----- ----- ----- ----- ----- ----- ----- ----- -----\n",
    "# [1ST TIME CODE EXECUTION] MANUAL VERIFICATIONS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'python' and 'pip' versions.\n",
    "\n",
    "!python --version\n",
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3492fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  List of installed packages.\n",
    "\n",
    "# !pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Validate MANUALLY, ONE AT A TIME, if packages are installed.\n",
    "\n",
    "!pip show sys | grep Version #  Built-in module, no need to install; only import.\n",
    "!pip show time | grep Version #  Built-in module, no need to install; only import.\n",
    "!pip show rich | grep Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [1ST TIME CODE EXECUTION] PACKAGES INSTALLATION: required for every NEW runtime.\n",
    "\n",
    "# #  To upgrade a package, add '-U' parameter before package name. e.g. '!pip install -U sys'.\n",
    "# # !pip install sys\n",
    "# # !pip install time\n",
    "# !pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LIBRARIES / PACKAGES IMPORTS.\n",
    "\n",
    "import sys\n",
    "from rich import print\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2335840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CODE EXECUTION\n",
    "\n",
    "#  Code reference: 'https://www.tiktok.com/@pyatsplusom/video/7535003211887889695'.\n",
    "#  Song: Lemon Demon - Fine\n",
    "# - URL: 'https://www.youtube.com/watch?v=xRiGeDMKpKU'.\n",
    "\n",
    "lines = [\n",
    "    (\". . .\", 0.2),\n",
    "    (\"Light is on the way\", 0.058),\n",
    "    (\"We'll be having a fun time\", 0.048),\n",
    "    (\"It's such a lovely day\", 0.048),\n",
    "    (\"We should pocket the sunshine\", 0.048),\n",
    "    (\"And never give it back\", 0.05),\n",
    "    (\"Even if there's a heat wave\", 0.04),\n",
    "    (\"Or terrorist attack\", 0.05),\n",
    "    (\"It will just be a close shave\", 0.05),\n",
    "    (\"I know\", 0.1),\n",
    "    (\"I know\", 0.15),\n",
    "    (\"That every bomb has a silver lining\", 0.07),\n",
    "    (\"I know\", 0.1),\n",
    "    (\"I know\", 0.1)\n",
    "]\n",
    "\n",
    "delays = [0.9, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.5, 1.2, 0.1, 0.1, 0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd190d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lines), \" | \", lines)\n",
    "print(len(delays), \" | \", delays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c308607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printLyrics():\n",
    "    for i, (line, char_delay) in enumerate(lines):\n",
    "        for char in line:\n",
    "            print(f\"[grey78]{char}[/grey78]\", end = '')\n",
    "            sys.stdout.flush()\n",
    "            sleep(char_delay)\n",
    "        print()\n",
    "        sleep(delays[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ce88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "printLyrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9963bb5",
   "metadata": {},
   "source": [
    "## Adjusted Version d250811.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80d310",
   "metadata": {},
   "source": [
    "- Original ref. '<https://www.tiktok.com/@pyatsplusom/video/7535003211887889695>'.\n",
    "- Additional ref. '<https://www.tiktok.com/@pyatsplusom/video/7536508737310231838>'.\n",
    "    - Clear function `clear = lambda: os.system('cls')`, `clear()`.\n",
    "- Additional ref. '<https://www.tiktok.com/@yahirdostingm/video/7537881992474414344>'.\n",
    "    - Color selection from list `color = man_colors[color_index % len(man_colors)...]`.\n",
    "- Additional ref. '<https://www.tiktok.com/@hilana.kp/video/7538456173717097784>'.\n",
    "    - `print` vs. `sys.stdout.write`: 'https://parseltongue.co.in/print-vs-sysstdoutwrite/'.\n",
    "- Additional ref. '<https://www.tiktok.com/@vladaobilic22/video/7537443540834553094>'.\n",
    "    - Add emoji at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ----- ----- ----- ----- ----- ----- ----- ----- -----\n",
    "# [1ST TIME CODE EXECUTION] MANUAL VERIFICATIONS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607efd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Distro. update.\n",
    "\n",
    "# !sudo apt update && sudo apt -y upgrade && sudo apt autoremove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Distro. 'python' and 'pip' versions.\n",
    "\n",
    "!python --version\n",
    "%pip --version          #  '!pip' vs '%pip': 'https://medium.com/@aroffe9/installing-python-packages-in-jupyter-notebooks-ca7dc7dd7535'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0487d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  List of installed packages.\n",
    "\n",
    "# %pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Validate MANUALLY, ONE AT A TIME, if packages are installed.\n",
    "\n",
    "# %pip show os | grep Verssion            #  Built-in module, no need to install; only import.\n",
    "%pip show rich | grep Version\n",
    "# %pip show warnings | grep Version       #  Built-in module, no need to install; only import.\n",
    "# %pip show glob | grep Version           #  Built-in module, no need to install; only import.\n",
    "# %pip show re | grep Version             #  Built-in module, no need to install; only import.\n",
    "%pip show PyYAML | grep Version\n",
    "# %pip show json | grep Version           #  Built-in module, no need to install; only import.\n",
    "# %pip show datetime | grep Version       #  Built-in module, no need to install; only import.\n",
    "# %pip show zoneinfo | grep Version       #  Built-in module, no need to install; only import.\n",
    "%pip show pandas | grep Version\n",
    "%pip show numpy | grep Version\n",
    "# %pip show copy | grep Version           #  Built-in module, no need to install; only import.\n",
    "# %pip show sys | grep Version            #  Built-in module, no need to install; only import.\n",
    "# %pip show time | grep Version           #  Built-in module, no need to install; only import.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b673f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  [1ST TIME CODE EXECUTION] PACKAGES INSTALLATION: required for every NEW runtime.\n",
    "\n",
    "# #  To upgrade a package, add '-U' parameter before package name. e.g. '!pip install -U sys'.\n",
    "# %pip install --upgrade pip setuptools           #  Keep pip, and complement updated: 'https://simpleaudio.readthedocs.io/en/latest/installation.html#installation', 'https://stackoverflow.com/questions/41216875/what-is-the-purpose-of-python-setuptools/41217568#41217568'.\n",
    "\n",
    "# # %pip install os\n",
    "# # %pip install rich                               #  Uses:  'https://www.freecodecamp.org/news/use-the-rich-library-in-python/'.\n",
    "# %pip install rich[jupyter]                      #  If intended to use rich with Jupyter: 'https://rich.readthedocs.io/en/stable/introduction.html#installation'.\n",
    "# # %pip install warnings\n",
    "# # %pip install glob\n",
    "# # %pip install re\n",
    "# %pip install PyYAML\n",
    "# # %pip install json\n",
    "# # %pip install datetime\n",
    "# # %pip install zoneinfo\n",
    "# %pip install pandas\n",
    "# # %pip install numpy\n",
    "# # %pip install copy\n",
    "# # %pip install sys\n",
    "# # %pip install time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LIBRARIES / PACKAGES IMPORTS.\n",
    "\n",
    "import os                                   #  To work with directories.\n",
    "from rich import print as rprint            #  Rich text and beautiful formatting.\n",
    "import warnings                             #  For showing warnings to developer.\n",
    "import glob                                 #  For listing files, using UNIX REGEX.\n",
    "import re                                   #  For REGEX, listing files, format validation of inputs, etc.\n",
    "import yaml                                 #  For managing input files in YAML format.\n",
    "import json                                 #  To convert Python objects (generally lists and dictionaries with appropiate structure) to JSONs strings (a.k.a. 'dumps'), and viceversa (a.k.a. 'loads').\n",
    "import datetime                             #  To manage dates, times, and time durations.\n",
    "import zoneinfo                             #  For timezones.\n",
    "import pandas as pd                         #  Dataframes, and csv's.\n",
    "import numpy as np                          #  Dataframes NaNs to None, and viceversa.\n",
    "import copy                                 #  For shallow and deep copies, specially oj objects such as dictionaries, dataframes, etc.\n",
    "import sys                                  #  To adjust default system output flush.\n",
    "from time import sleep                      #  To manage pauses on code execution, for lyrics / song lines display.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  USER DEFINEND FUNCTIONS (UDFs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Validate if a DIRECTORY path exists, and creates it (optionally, True by default) if it doesn't exist.\n",
    "def UDFValidateDirectoryExists(IPath: str, ICreateDir: bool = True) -> None:\n",
    "    if (not os.path.exists(IPath)):\n",
    "        warnings.warn(f\"[WARNING] Directory '{IPath}' should exist in order for current script to run properly.\")\n",
    "        if (ICreateDir):\n",
    "            rprint(f\"[LOG] Creating directory: '{IPath}'.\")\n",
    "            os.mkdir(IPath)\n",
    "    else:\n",
    "        rprint(f\"[LOG] Directory found: '{IPath}'.\")\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Search for basename paths (i.e. files OR directories), starting from a given directory (CURRENT working directory, if not provided) in a RECURSIVELY manner.\n",
    "def UDFSearchPaths(IBasename: str, IDirpath: str = '**') -> list:\n",
    "    basename_regex = IBasename.encode('unicode-escape').decode('unicode-escape') + r'$'     #  Python raw strings and RegEx: 'https://www.digitalocean.com/community/tutorials/python-raw-string'.\n",
    "    search_space_pattern = IDirpath if (IDirpath == '**') else (IDirpath + '/**')\n",
    "    filepaths_list = [i for i in glob.iglob(search_space_pattern, recursive = True) if re.search(basename_regex, i, re.IGNORECASE)]     #  RegEx re.search() vs. re.match(): 'https://www.geeksforgeeks.org/python/python-re-search-vs-re-match/'.\n",
    "    #  Throws an AssertionError, if no path found.\n",
    "    assert len(filepaths_list) > 0, f\"[ERROR] File or directory called '{basename_regex[:-1]}' (after unicode escaping) should exist in order for current script to run properly.\"\n",
    "    \n",
    "    return filepaths_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae86e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [AUXILIARY] Prettify JSONs; i.e. converts Python object (generally lists and dictionaries with appropiate structure) to JSON string (a.k.a. 'dumps'). Ref. 'https://www.dataquest.io/blog/api-in-python/'.\n",
    "def UDFJsonPrint(IObject) -> None:\n",
    "    text = json.dumps(IObject, sort_keys = False, indent = 4)\n",
    "    print(text)\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b04b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Converts to basic* data types; it requires at MINIMUM: value to convert, and specify it's data type.\n",
    "#  - *No-iterables: null, boolean, string, integer, decimal, complex, and numeric range (last one, returns a list).\n",
    "#  - *Iterables: list, tuple, and set. These requiere additionally specification of the data subtype (i.e. type of their elements).\n",
    "#  It returns the converted value, or 'None' if any mistake on the inputs like:\n",
    "#  - The data type is not of any of the basic* data types.\n",
    "def UDFConvertToBasicDataTypes(IValue, IDataType: str, IDataSubType = None):\n",
    "    \n",
    "    value_string                = str(IValue).strip()           #  It tries ALWAYS to convert value to string, as a starting point.\n",
    "    data_type                   = str(IDataType).strip()        #  It tries ALWAYS to convert the input of data type to string, and clean it.\n",
    "    data_subtype                = str(IDataSubType).strip() if (IDataSubType is not None) else (None)   #  By default is 'None'; otherwise, try to clean it.\n",
    "    value_converted             = None\n",
    "    DATA_TYPES                  = (\n",
    "        'null', 'boolean', 'string', 'integer', 'decimal', 'complex', 'range'\n",
    "        , 'date and/or time (with or without timezone)'\n",
    "        , 'time duration'\n",
    "        , 'list', 'tuple', 'set'\n",
    "    )\n",
    "    DATA_TYPES_FOR_ITERABLES    = (\n",
    "        'null', 'boolean', 'string', 'integer', 'decimal', 'complex', 'range'\n",
    "        , 'date and/or time (with or without timezone)'\n",
    "        , 'time duration'\n",
    "    )\n",
    "\n",
    "    if data_type not in DATA_TYPES:\n",
    "        value_converted = None\n",
    "    else:\n",
    "        if data_type == 'null':\n",
    "            value_converted = None\n",
    "        if data_type == 'boolean':\n",
    "            value_converted = True if (value_string.lower().capitalize() == 'True') else (False)\n",
    "        if data_type == 'string':\n",
    "            value_converted = value_string\n",
    "        if data_type == 'integer':\n",
    "            value_converted = int(value_string)\n",
    "        if data_type == 'decimal':\n",
    "            value_converted = float(value_string)\n",
    "        if data_type == 'complex':\n",
    "            value_converted = complex(value_string)\n",
    "        if data_type == 'range':\n",
    "            value_converted = list(range(int(value_string)))\n",
    "        if data_type == 'date and/or time (with or without timezone)':\n",
    "            date_time_timezone_format = ''\n",
    "            date_time = None\n",
    "            date_time_timezone = None\n",
    "            #  RegEx expression for searching matches:\n",
    "            #+ YYYY/MM/DD HH:MM:SS.X[+/-]timezone(in HHMM),\n",
    "            #+ where YYYY: [1900, 2099], MM: [01, 12], DD: [01, 31], HH: [00, 23], MM: [00, 59], SS: [00, 59], X: [0, 999999].\n",
    "            #+ e.g. '2011/08/15 12:45:01.095673-0500'.\n",
    "            #  Test at 'https://regex101.com'.\n",
    "            date_time_timezone_regex = r'^(?P<date>(?P<year>(19|20)\\d{2})/(?P<month>0[1-9]|1[0-2])/(?P<day>0[1-9]|[12][0-9]|3[0-1])\\b)? ?(?P<time>\\b(?P<hour>[01][0-9]|2[0-3]):(?P<min>[0-5][0-9]):(?P<sec>[0-5][0-9])(\\.(?P<microsec>\\d{1,6}))?(?P<timezone>(?P<timezone_sign>[+-])(?P<timezone_hour>[01][0-9]|2[0-3])(?P<timezone_min>[0-5][0-9]))?)?$'\n",
    "            regex_match = re.search(date_time_timezone_regex, value_string)    #  If using re.match(), date_time_timezone_regex = r'...' DOESN'T require '^'; i.e. RegEx re.search() vs. re.match(): 'https://www.geeksforgeeks.org/python/python-re-search-vs-re-match/'.\n",
    "            if regex_match is not None:\n",
    "                #  e.g. '2011/08/15 12:45:01.095673-0500'.\n",
    "                #  date_time_timezone_format = '%Y/%m/%d %H:%M:%S.%f%z'    :date+time+tz    : datetime.datetime.strptime(value_string, date_time_timezone_format) > datetime.datetime.\n",
    "                #  date_time_timezone_format = '%Y/%m/%d %H:%M:%S.%f'      :date+time       : datetime.datetime.strptime(value_string, date_time_timezone_format) > datetime.datetime.\n",
    "                #  date_time_timezone_format = '%Y/%m/%d %H:%M:%S'         :date+time       : datetime.datetime.strptime(value_string, date_time_timezone_format) > datetime.datetime.\n",
    "                #  date_time_timezone_format = '%Y/%m/%d'                  :date            : datetime.datetime.strptime(value_string, date_time_timezone_format) > datetime.date.\n",
    "                #  date_time_timezone_format = '%H:%M:%S'                  :time            : datetime.datetime.strptime(value_string, date_time_timezone_format) > datetime.time.\n",
    "                #  date_time_timezone_format = '%H:%M:%S.%f'               :time            : datetime.datetime.strptime(value_string, date_time_timezone_format) > datetime.time.\n",
    "                #  date_time_timezone_format = '%H:%M:%S.%f%z'             :time+tz         : datetime.datetime.strptime(value_string, date_time_timezone_format) > datetime.time.\n",
    "                term = (regex_match.group('date') is not None, regex_match.group('time') is not None, regex_match.group('microsec') is not None, regex_match.group('timezone') is not None)\n",
    "                match term:\n",
    "                    case (True, True, True, True):          #  e.g. '2011/08/15 12:45:01.095673-0500'.\n",
    "                        date_time_timezone_format           = '%Y/%m/%d %H:%M:%S.%f%z'\n",
    "                        date_time                           = datetime.datetime.strptime(value_string, date_time_timezone_format)\n",
    "                        date_time_timezone                  = date_time\n",
    "                    case (True, True, True, False):         #  e.g. '2011/08/15 12:45:01.095673'.\n",
    "                        date_time_timezone_format           = '%Y/%m/%d %H:%M:%S.%f'\n",
    "                        date_time                           = datetime.datetime.strptime(value_string, date_time_timezone_format)\n",
    "                        date_time_timezone                  = date_time\n",
    "                    case (True, True, False, False):        #  e.g. '2011/08/15 12:45:01'.\n",
    "                        date_time_timezone_format           = '%Y/%m/%d %H:%M:%S'\n",
    "                        date_time                           = datetime.datetime.strptime(value_string, date_time_timezone_format)\n",
    "                        date_time_timezone                  = date_time\n",
    "                    case (True, False, False, False):       #  e.g. '2011/08/15'.\n",
    "                        date_time_timezone_format           = '%Y/%m/%d'\n",
    "                        date_time                           = datetime.datetime.strptime(value_string, date_time_timezone_format)\n",
    "                        date_time_timezone                  = date_time.date()\n",
    "                    case (False, True, False, False):       #  e.g. '12:45:01'.\n",
    "                        date_time_timezone_format           = '%H:%M:%S'\n",
    "                        date_time                           = datetime.datetime.strptime(value_string, date_time_timezone_format)\n",
    "                        date_time_timezone                  = date_time.time()\n",
    "                    case (False, True, True, False):        #  e.g. '12:45:01.095673'.\n",
    "                        date_time_timezone_format           = '%H:%M:%S.%f'\n",
    "                        date_time                           = datetime.datetime.strptime(value_string, date_time_timezone_format)\n",
    "                        date_time_timezone                  = date_time.time()\n",
    "                    case (False, True, True, True):         #  e.g. '12:45:01.095673-0500'. NOTE: timezone data will be lost, since only a 'datetime.datetime' object can store timezone data; not 'datetime.date' nor 'datetime.time' alone.\n",
    "                        date_time_timezone_format           = '%H:%M:%S.%f%z'\n",
    "                        date_time                           = datetime.datetime.strptime(value_string, date_time_timezone_format)\n",
    "                        date_time_timezone                  = date_time.time()\n",
    "                    case _:                                 #  'Default'.\n",
    "                        warnings.warn(f\"Entry: '{value_string}' doesn't match the format; entry won't be processed. Please review it follows the format: 'YYYY/MM/DD HH:MM:SS.X[+/-]timezone(in HHMM)', where YYYY: [1900, 2099], MM: [01, 12], DD: [01, 31], HH: [00, 23], MM: [00, 59], SS: [00, 59], X: [0, 999999]; e.g. '2011/08/15 12:45:01.095673-0500'.\")\n",
    "            else:\n",
    "                warnings.warn(f\"Entry: '{value_string}' doesn't match the format; entry won't be processed. Please review it follows the format: 'YYYY/MM/DD HH:MM:SS.X[+/-]timezone(in HHMM)', where YYYY: [1900, 2099], MM: [01, 12], DD: [01, 31], HH: [00, 23], MM: [00, 59], SS: [00, 59], X: [0, 999999]; e.g. '2011/08/15 12:45:01.095673-0500'.\")\n",
    "            value_converted = date_time_timezone\n",
    "        if data_type == 'time duration':\n",
    "            time_delta = None\n",
    "            #  Format for time splitting:\n",
    "            #+ HH:MM:SS,\n",
    "            #+ where HH: number (integer or decimal), MM: number (integer or decimal), SS: number (integer or decimal).\n",
    "            #+ e.g. 2 days > 24h*2 > '48:00:00'; 36 min and 2.56 sec > '36:2.56'.\n",
    "            term = tuple(map(float, value_string.split(':')))\n",
    "            match term:\n",
    "                case (split_hours, split_minutes, split_seconds):\n",
    "                    time_delta = datetime.timedelta(hours = split_hours, minutes = split_minutes, seconds = split_seconds)\n",
    "                case (split_minutes, split_seconds):\n",
    "                    time_delta = datetime.timedelta(minutes = split_minutes, seconds = split_seconds)\n",
    "                case (split_seconds, ):\n",
    "                    time_delta = datetime.timedelta(seconds = split_seconds)\n",
    "                case _:                                     #  'Default'.\n",
    "                    warnings.warn(f\"Entry: '{value_string}' doesn't match the format; entry won't be processed. Please review it follows the format: 'HH:MM:SS', where HH: number (integer or decimal), MM: number (integer or decimal), SS: number (integer or decimal); e.g. 2 days > 24h*2 > '48:00:00'; 36 min and 2.56 sec > '36:2.56'\")\n",
    "                    # time_delta = datetime.timedelta()     # '0:00:00'. If ever required in a future, but right now, default return for no matches is 'None'.\n",
    "            value_converted = time_delta\n",
    "        if data_subtype in DATA_TYPES_FOR_ITERABLES:            #  To avoid INFINITE RECURSIVENESS; e.g. data_type: 'list', and data_subtype: 'tuple'.\n",
    "            #  Use of 'map()' to apply a function to iterable(s): 'https://www.geeksforgeeks.org/python/python-map-function/', 'https://www.w3schools.com/python/ref_func_map.asp'.\n",
    "            #  Repeat an element, several times in a list: 'https://stackoverflow.com/questions/3459098/create-list-of-single-item-repeated-n-times/3459131#3459131'.\n",
    "            if data_type == 'list':\n",
    "                value_converted = list(map(UDFConvertToBasicDataTypes, value_string.split('|'), [data_subtype] * len(value_string.split('|'))))\n",
    "            if data_type == 'tuple':\n",
    "                value_converted = tuple(map(UDFConvertToBasicDataTypes, value_string.split('|'), [data_subtype] * len(value_string.split('|'))))\n",
    "            if data_type == 'set':\n",
    "                value_converted = set(map(UDFConvertToBasicDataTypes, value_string.split('|'), [data_subtype] * len(value_string.split('|'))))\n",
    "\n",
    "    return value_converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f139043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creates a dictionary of variables, with proper data conversion.\n",
    "#  - IT REQUIRES CUSTOM FUNCTION UDFConvertToBasicDataTypes().\n",
    "#  - Input is a LIST in proper format for each variable:\n",
    "#+ [ { 'name': <variable_name>, 'type': <variable_type_from_UDFConvertToBasicDataTypes()>, 'subtype': <variable_subtype_from_UDFConvertToBasicDataTypes()>,\n",
    "#+ 'comment': <variable_comment>, 'value': <variable_value> }, { ... } ].\n",
    "#  - Output format: { <variable1_name> : <variable1_value>, <variable2_name> : <variable2_value>, ...}.\n",
    "def UDFCreateVariablesDictionaryFromFormattedList(IList: list) -> dict:\n",
    "    variables_dictionary  = {}\n",
    "    \n",
    "    for index, variable in enumerate(IList):                                                        #  Get index of a list iterator: 'https://www.stellargrove.com/how-to-blog/find-the-index-of-the-iterator-of-a-list'.\n",
    "        (variable_name, variable_type, variable_subtype, variable_comment, variable_value)          = \\\n",
    "        (variable['name'], variable['type'], variable['subtype'], variable['comment'], variable['value'])\n",
    "        #  Validates MINIMUM fields for a variable to be valid; e.g. 'name', and 'type'. Ref. 'https://ellibrodepython.com/assert-python'.\n",
    "        assert all([\n",
    "            variable_name is not None, variable_type is not None\n",
    "            ]), f\"[Variable number '{index + 1}'] In order for a variable to be processed, it requires at MINIMUM: a 'name', and 'type' defined; at least 1 is missing.\"\n",
    "        \n",
    "        variable_name_clean                         = str(variable_name).strip()\n",
    "        variable_type_clean                         = str(variable_type).strip()\n",
    "        variable_subtype_clean                      = str(variable_subtype).strip() if (variable_subtype is not None) else (None)\n",
    "\n",
    "        #  Data transformation.\n",
    "        variables_dictionary[variable_name_clean]   = UDFConvertToBasicDataTypes(variable_value, variable_type_clean, variable_subtype_clean)\n",
    "\n",
    "    return variables_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load variables from formatted dictionary into globals().\n",
    "def UDFLoadVariablesToGlobals(IDictionary: dict) -> None:\n",
    "    for variable_name, variable_value in IDictionary.items():\n",
    "        globals()[variable_name] = variable_value\n",
    "    rprint(f\"[LOG] Variables loaded to 'globals()' (x{len(IDictionary)}): '{\"' | '\".join([*IDictionary.keys()])}'.\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load CSV, SPECIFIC to user parameters; e.g. 'py3-song_lyrics_terminal_console_display-v250811-input_user_params.csv'.\n",
    "#  - Input is a csv file in proper format:\n",
    "#+ a. csv file MUST NOT have a header.\n",
    "#+ b. EACH csv record MUST BE in format: '<variable_name>, <variable_value>'.\n",
    "#  - Output: a dictionary containing objects.\n",
    "#+ Format is { '<object1_name>': <object1>, '<object2_name>': <object2>, ... }\n",
    "def UDFLoadCSVUserParameters(ICsvFilepath: str) -> list:\n",
    "    objects_dictionary = {}\n",
    "\n",
    "    #  Pandas dataframe custom parameters. 'dtypes' list available at: 'https://pandas.pydata.org/docs/user_guide/basics.html#dtypes'.\n",
    "    DATAFRAME_COLUMN_TYPES = {'name': 'string', 'value': object}\n",
    "    DATAFRAME_COLUMN_NAMES = list(DATAFRAME_COLUMN_TYPES.keys())\n",
    "\n",
    "    #  Create Pandas dataframe, from '.csv' file: 'https://www.datacamp.com/tutorial/pandas-read-csv', 'https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html'.\n",
    "    #  - Forces NOT to create header from file.\n",
    "    #  - Header with column names will be provided with list 'DATAFRAME_COLUMN_NAMES'; e.g. 'name', and 'value'.\n",
    "    #  - Columns data types will be provided with list 'DATAFRAME_COLUMN_TYPES'; e.g. dtype 'string' for 'name', and dtype 'object' for 'value' (to keep intended original value).\n",
    "    user_variables_dataframe = pd.read_csv(ICsvFilepath, header = None, names = DATAFRAME_COLUMN_NAMES, dtype = DATAFRAME_COLUMN_TYPES)\n",
    "\n",
    "    #  Remapping of new values, matching to indexes.\n",
    "    name_dictionary         = {\n",
    "        0: 'user_song_lines_file'\n",
    "    }\n",
    "    type_dictionary         = {\n",
    "        0: 'string'\n",
    "    }\n",
    "    subtype_dictionary      = {\n",
    "        0: None\n",
    "    }\n",
    "    comment_dictionary      = {\n",
    "        0: \"POSITION 0 (row 1): 'user_song_lines_file'. Variable for choosing which song lines file to play, using the file's name; e.g. 'song_lines-lemon_demon-fine.csv'.\"\n",
    "    }\n",
    "    # value_dictionary        = {0: ...}  #  Not used since it's provided by user.\n",
    "\n",
    "    #  Remap columns data with additional details of variables.\n",
    "    #+ NOTE: entries already in the dataframe with no match in previously defined dictionaries, will be LOST; i.e. get a value of 'NaN'.\n",
    "    user_variables_dataframe['name']        = user_variables_dataframe.index.map(name_dictionary)\n",
    "    #  New columns, with python dictionary: 'https://builtin.com/data-science/pandas-add-column'.\n",
    "    user_variables_dataframe['type']        = user_variables_dataframe.index.map(type_dictionary)\n",
    "    user_variables_dataframe['subtype']     = user_variables_dataframe.index.map(subtype_dictionary)\n",
    "    user_variables_dataframe['comment']     = user_variables_dataframe.index.map(comment_dictionary)\n",
    "\n",
    "    #  Clean dataframe.\n",
    "    column_order_list                       = ['name', 'type', 'subtype', 'comment', 'value']           #  Rearrange columns order: define order with list.\n",
    "    user_variables_dataframe                = user_variables_dataframe[column_order_list]               #  Rearrange columns order.\n",
    "    user_variables_dataframe                = user_variables_dataframe.replace(np.nan, None)            #  Clean nulls ('NaN's to 'None'): 'https://www.statology.org/pandas-replace-nan-with-none/'.\n",
    "    user_variables_dataframe                = user_variables_dataframe[\n",
    "        user_variables_dataframe['name'].apply(lambda x : x is not None)]                               #  Filter rows with 'name' entries valid; i.e. not 'None'.\n",
    "    # rprint(user_variables_dataframe.isnull())                                                           #  Quick check of null values.\n",
    "\n",
    "    # #  NOTES ON ACCESSING CELLS, ROWS AND COLUMNS WITHIN A DATAFRAME.\n",
    "    # #\n",
    "    # #  DATAFRAME QUICK VIEW:\n",
    "    # rprint(\n",
    "    #     user_variables_dataframe.info(), '---',\n",
    "    #     user_variables_dataframe.head(), '---',\n",
    "    #     user_variables_dataframe.describe(), '---',\n",
    "    #     sep = '\\n\\n'\n",
    "    # )\n",
    "    # #\n",
    "    # #  HOW TO ACCESS A CELL OF A DATAFRAME:                                                                                 : 'https://stackoverflow.com/questions/28757389/pandas-loc-vs-iloc-vs-at-vs-iat/30022658#30022658'.\n",
    "    # #  - '.at'      : access SINGLE CELL using labels (i.e. indexes for rows, names for columns) and filters.               : 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at'.\n",
    "    # #  - '.iat'     : access SINGLE CELL using positions (i.e. position [x,y], starting at [0, 0]). NO FILTERS.             : 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iat.html'.\n",
    "    # #  - '.loc'     : access SEVERAL cells (groups) using labels.                                                           : 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc'.\n",
    "    # #  - '.iloc'    : access SEVERAL cells (groups) using positions (positions end at [shape[0] - 1, shape[1] - 1]).        : 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc'.\n",
    "    # #  - '.loc' vs '.iloc' examples.                                                                                        : 'https://www.datacamp.com/tutorial/loc-vs-iloc'.\n",
    "    # rprint(user_variables_dataframe.iat[0,4])                                                                               #  GET cell value (e.g. as a string) in dataframe POSITION [0, 4]; i.e. row = 0, column = 4.\n",
    "    # user_variables_dataframe.at[0, 'name'] = 'user_song_lines_file'                                                         #  SET cell value in dataframe referenced by LABELS: row INDEX (not POSITION) = 0, column CALLED = 'name'.\n",
    "    # #  - Filtering dataframe and getting cell values (a.k.a. 'scalar')                                                      : 'https://stackoverflow.com/questions/65829774/how-to-get-the-value-of-a-cell-based-on-filtering-efficently/65829854#65829854'.\n",
    "    # #  - Use '.values' to get cell values (a.k.a. 'scalar')                                                                 : 'https://stackoverflow.com/questions/70422875/difference-between-values-and-iloc-on-a-pandas-series/70422985#70422985'.\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file'])                        #  GET rows (and columns; as a dataframe, 'filtered'), where cell (row) value is 'user_song_lines_file' in column 'name'.\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file'].values)                 #  GET rows (and columns; as numpy array (similar to a list)), where cell (row) value is 'user_song_lines_file' in column 'name'.\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file'].values[0])              #  GET 1st row (and columns; as numpy array (similar to a list)), from previous numpy array example.\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file'].values[0][4])           #  GET value (e.g. as a string) of 'column' 4 (more like item in POSITON 4), from previous numpy array example.\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file'].iat[0, 4])              #  GET cell value (e.g. as a string) from 'filtered' dataframe in last previous dataframe results example.\n",
    "    # #\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file', 'value'])               #  GET column (and rows; as pandas series, 'filtered') called 'value', where cell (row) value is 'user_song_lines_file' in column 'name'.\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file', 'value'].values)        #  GET column (and rows; as numpy array (similar to a list)), where cell (row) value is 'user_song_lines_file' in column 'name'.\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file', 'value'].values[0])     #  GET 1st value (e.g. as a string), from previous numpy array example. Unlike previous example section, the filtering of 'column 4' was not necessary, since it was done in the 1st filtering (as a pandas series).\n",
    "    # rprint(user_variables_dataframe.loc[user_variables_dataframe['name'] == 'user_song_lines_file', 'value'].iat[0])        #  GET cell value (e.g. as a string) from 'filtered' pandas series in last previous pandas series results example.\n",
    "\n",
    "    #  Transforms dataframe into dictionary with proper format: 'https://stackoverflow.com/questions/26716616/convert-a-pandas-dataframe-to-a-dictionary/26716774#26716774'.\n",
    "    user_variables_list = user_variables_dataframe.to_dict(orient = 'records')\n",
    "\n",
    "    rprint(f\"[LOG] Variables imported in total (x{len(user_variables_list)}), from: '{ICsvFilepath}'.\")\n",
    "\n",
    "    #  Return objects in a dictionary.\n",
    "    #+ 'copy.deepcopy()' function should be used outside of this function, whenever is called. Putting it here, would be inefficient in terms of memory.\n",
    "    #+ Ref. 'https://www.geeksforgeeks.org/python/copy-python-deep-copy-shallow-copy/'.\n",
    "    objects_dictionary = {\n",
    "        'user_variables_dataframe': user_variables_dataframe,\n",
    "        'user_variables_list': user_variables_list\n",
    "    }\n",
    "\n",
    "    return objects_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3382d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load CSV, SPECIFIC to song lines; e.g. 'song_lines-lemon_demon-fine.csv'.\n",
    "#  - Input is a csv file in proper format:\n",
    "#+ a. csv file MUST have a header with 'column' names: 'line', 'line_character_delay', 'line_repetition', and 'line_end_delay'.\n",
    "#+ b. EACH csv record MUST BE of type: 'string, float, integer, float'.\n",
    "#  - Output: a dictionary containing objects.\n",
    "#+ Format is { '<object1_name>': <object1>, '<object2_name>': <object2>, ... }\n",
    "def UDFLoadCSVSongLines(ICsvFilepath: str) -> list:\n",
    "    objects_dictionary = {}\n",
    "\n",
    "    #  Pandas dataframe custom parameters. 'dtypes' list available at: 'https://pandas.pydata.org/docs/user_guide/basics.html#dtypes'.\n",
    "    DATAFRAME_COLUMN_TYPES = {'line': 'string', 'line_character_delay': 'Float64', 'line_repetition': 'Int64', 'line_end_delay': 'Float64'}\n",
    "    DATAFRAME_COLUMN_NAMES = list(DATAFRAME_COLUMN_TYPES.keys())\n",
    "\n",
    "    #  Create Pandas dataframe, from '.csv' file: 'https://www.datacamp.com/tutorial/pandas-read-csv', 'https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html'.\n",
    "    #  - Forces to avoid creating header from file, ommiting line 0 (first data point).\n",
    "    #  - Header with column names will be provided with list 'DATAFRAME_COLUMN_NAMES'; e.g. 'name', and 'value'.\n",
    "    #  - Columns data types will be provided with list 'DATAFRAME_COLUMN_TYPES'; e.g. dtype 'string' for 'name', and dtype 'object' for 'value' (to keep intended original value).\n",
    "    song_lines_dataframe = pd.read_csv(ICsvFilepath, header = 0, names = DATAFRAME_COLUMN_NAMES, dtype = DATAFRAME_COLUMN_TYPES)\n",
    "\n",
    "    #  Transforms dataframe into list of tuples: 'https://blog.finxter.com/python-create-list-of-tuples-from-dataframe/'.\n",
    "    song_lines_list = [tuple(row) for index, row in song_lines_dataframe.iterrows()]\n",
    "\n",
    "    rprint(f\"[LOG] Song lyrics (lines) imported (x{len(song_lines_list)}), from: '{ICsvFilepath}'.\")\n",
    "\n",
    "    #  Return objects in a dictionary.\n",
    "    #+ 'copy.deepcopy()' function should be used outside of this function, whenever is called. Putting it here, would be inefficient in terms of memory.\n",
    "    #+ Ref. 'https://www.geeksforgeeks.org/python/copy-python-deep-copy-shallow-copy/'.\n",
    "    objects_dictionary = {\n",
    "        'song_lines_dataframe': song_lines_dataframe,\n",
    "        'song_lines_list': song_lines_list\n",
    "    }\n",
    "\n",
    "    return objects_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd777702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [Fast user defined function (UDF) definition] Clear terminal / console output.\n",
    "#  [OP01] Traditional way.\n",
    "# def UDFClearOutput() -> None:\n",
    "#     os.system('clear')      #  Executes os function called 'clear'. Either in Linux or Windows, clear() clears terminal / console / CLI output.\n",
    "#     return None\n",
    "#\n",
    "#  [OP02] Using lambda, anonymous / nameless functions. Ref. 'https://www.freecodecamp.org/news/lambda-expressions-in-python/', 'https://www.geeksforgeeks.org/python/python-lambda-anonymous-functions-filter-map-reduce/'.\n",
    "UDFClearOutput = lambda: os.system('clear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Core function of displaying song lyrics / lines.\n",
    "#  - IT REQUIRES CUSTOM FUNCTION UDFClearOutput().\n",
    "#  - Input is 1. a list of tuples; a list for a single song, with each tuple representing a song line,\n",
    "#+ and 2. an integer defining the regular lines interval for clearing the console / terminal / CLI.\n",
    "#+ Format follows requirements of function UDFLoadCSVSongLines() for each csv record.\n",
    "#  NOTE: output is not properly rendered in Jupyter Notebooks.\n",
    "def UDFSongLinesTypewriter(ISongLinesList: list, ILinesIntervalOutputClearing: int) -> None:\n",
    "    line_counter = 0        #  Counter to determine when to clear console / terminal / CLI output.\n",
    "    UDFClearOutput()\n",
    "\n",
    "    #  Iterates over each song line.\n",
    "    for i, (line, line_character_delay, line_repetition, line_end_delay) in enumerate(ISongLinesList):\n",
    "        if (line_repetition == 1): line_counter += 1                #  Only count lines for regular song lines; i.e. ones that 'play' ONCE, unlike lines such as '[delay]' or '. . .', that will repeat more than ONCE (i.e. line_repetition > 1).\n",
    "        line_repetition_backward_counter = line_repetition - 1      #  For non-regular song lines, such as delay flags (e.g. '[delay]', '. . .'), it will display the counter in the console / terminal / CLI.\n",
    "\n",
    "        for j in range(line_repetition):                            #  For regular song lines, it will iterate only ONCE.\n",
    "            line_repetition_text = '' if (line_repetition == 1) else (' x' + str(line_repetition_backward_counter))\n",
    "            line_adjusted = line + line_repetition_text             #  Adds backwards counter to text if line repeats more than ONCE; empty otherwise.\n",
    "            \n",
    "            for line_character in line_adjusted:                    #  Iterates over the line, showing one character at a time.\n",
    "                rprint(f'[gold1]{line_character}[/gold1]', end = '')\n",
    "                sys.stdout.flush()                                  #  Forces terminal to print a character: 'https://stackoverflow.com/questions/10019456/usage-of-sys-stdout-flush-method/10019605#10019605', 'https://medium.com/@hhtg250/stdin-stdout-flush-and-buffering-in-python-e747b85cb6ae'.\n",
    "                sleep(line_character_delay)\n",
    "            \n",
    "            rprint()\n",
    "            if line_repetition != 1: UDFClearOutput()               #  Clears output, if it's a non-regular song line.\n",
    "            line_repetition_backward_counter -= 1\n",
    "\n",
    "        sleep(line_end_delay)\n",
    "\n",
    "        if (line_counter == ILinesIntervalOutputClearing):          #  Clears output and resets line counter, if reaches user-defined regular song lines to show.\n",
    "            UDFClearOutput()\n",
    "            line_counter = 0\n",
    "    \n",
    "    UDFClearOutput()                                                #  Clears output when finalizing song.\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa4961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  INPUTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Main directory.\n",
    "\n",
    "_PROJECT_BASE_FILENAME       = 'py3-song_lyrics_terminal_console_display'\n",
    "_VERSION_NAME                = 'v250811'\n",
    "\n",
    "home_dirpath = None\n",
    "#  How to get a python filepath: 'https://note.nkmk.me/en/python-script-file-path/'.\n",
    "#  How to get a python filepath, considering Jupyter Notebooks: 'https://medium.com/@jennycoreholt/how-to-professionally-import-external-files-in-jupyter-notebooks-4000f1ce16f7'.\n",
    "if '__file__' in globals():\n",
    "    file_filepath   = None\n",
    "    #  If it's a regular python file / module: 'https://stackoverflow.com/questions/38412495/difference-between-os-path-dirnameos-path-abspath-file-and-os-path-dirnam/38412504#38412504', 'https://community.esri.com/t5/python-blog/finding-python-script-home-folder/bc-p/884009/highlight/true'.\n",
    "    #  Alternative: 'https://saturncloud.io/blog/how-to-obtain-jupyter-notebooks-path/'.\n",
    "    file_filepath   = os.path.abspath(__file__)\n",
    "    home_dirpath    = os.path.dirname(file_filepath)\n",
    "else:\n",
    "    #  If it's a Jupyter Notebook: 'https://stackoverflow.com/questions/39125532/file-does-not-exist-in-jupyter-notebook/53958599#53958599', 'https://forums.fast.ai/t/file-dunder-attribute-works-in-py-not-in-notebook/102400/7'.\n",
    "    home_dirpath    = str(globals()['_dh'][0])\n",
    "\n",
    "#  Input: data.\n",
    "input_dirpath_relative_to_home                      = 'io_dir-input'        #  Dirpath relative to home directory.\n",
    "input_configuration_dirpath_relative_to_home        = os.path.join(input_dirpath_relative_to_home, 'config')        #  Directory for configuration files.\n",
    "input_user_parameters_dirpath_relative_to_home      = os.path.join(input_dirpath_relative_to_home, 'user_params')   #  Directory for input user instructions, if required.\n",
    "input_user_files_dirpath_relative_to_home           = os.path.join(input_dirpath_relative_to_home, 'user_files')    #  Directory for user files, if input required.\n",
    "\n",
    "input_configuration_filenames_regex     = _PROJECT_BASE_FILENAME + '-' + _VERSION_NAME + r'-input_.*\\.yaml'           #  String literal for RegEx expresion of configuration filenames patterns; e.g. '...-input-<...>.yaml': 'https://www.w3schools.com/python/python_regex.asp', 'https://regex101.com'. Files listing base variables and their structure; e.g. user timezone, column names for dataframes, etc. NOTE: all matching files will be processed the SAME WAY.\n",
    "input_user_parameters_filename          = _PROJECT_BASE_FILENAME + '-' + _VERSION_NAME + r'-input_user_params.csv'    #  File listing variables that require input from user; e.g. copy or cut?, file to read, etc. Usually variables used here, SHOULD BE PRE-DECLARED in a YAML configration file; e.g. in 'py3-song_lyrics_terminal_console_display-v250811-input_config.yaml'.\n",
    "input_user_files_filename_regex         = r'song_lines-.*\\.csv'                                                     #  String literal for RegEx expresion of user filenames patterns; e.g. 'song_lines-<...>.csv': 'https://www.w3schools.com/python/python_regex.asp', 'https://regex101.com'. NOTE: all matching files will be processed the SAME WAY.\n",
    "\n",
    "#  Output.\n",
    "output_dirpath_relative_to_home         = 'io_dir-output'                   #  Dirpath relative to home directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372bc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  INITIALIZATION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb349c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print current working directory.\n",
    "working_directory = os.getcwd()\n",
    "rprint(f\"[LOG] Current working directory: '{working_directory}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set working directory to 'home'.\n",
    "rprint(f\"[LOG] Changing current working directory to: '{home_dirpath}'.\")\n",
    "os.chdir(home_dirpath)\n",
    "working_directory = os.getcwd()\n",
    "rprint(f\"[LOG] Current working directory: '{working_directory}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d935360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [INITIALIZATION] PROJECT BASE STRUCTURE VALIDATION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a79e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Inputs validations: wheter or not exists input directory.\n",
    "UDFValidateDirectoryExists(input_dirpath_relative_to_home)\n",
    "\n",
    "#  Inputs validations: wheter or not exists configuration sub-directory (of input directory).\n",
    "#  NOTE: it REQUIRES parent directory (input directory) to exist.\n",
    "UDFValidateDirectoryExists(input_configuration_dirpath_relative_to_home)\n",
    "\n",
    "#  Inputs validations: wheter or not exists user parameters sub-directory (of input directory).\n",
    "#  NOTE: it REQUIRES parent directory (input directory) to exist.\n",
    "UDFValidateDirectoryExists(input_user_parameters_dirpath_relative_to_home)\n",
    "\n",
    "#  Inputs validations: wheter or not exists user files sub-directory (of input directory).\n",
    "#  NOTE: it REQUIRES parent directory (input directory) to exist.\n",
    "UDFValidateDirectoryExists(input_user_files_dirpath_relative_to_home)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Outputs validations: wheter or not exists output directory.\n",
    "UDFValidateDirectoryExists(output_dirpath_relative_to_home)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Inputs validations: searches for configuration of base variables.\n",
    "input_configuration_filepaths_relative_to_home          = UDFSearchPaths(input_configuration_filenames_regex, input_configuration_dirpath_relative_to_home)\n",
    "#  Inputs validations: searches for user parameters file.\n",
    "input_user_parameters_filepaths_relative_to_home        = UDFSearchPaths(input_user_parameters_filename, input_user_parameters_dirpath_relative_to_home)\n",
    "#  Inputs validations: searches for user files required as input, besides parameters, using REGEX.\n",
    "input_user_files_filepaths_relative_to_home             = UDFSearchPaths(input_user_files_filename_regex, input_user_files_dirpath_relative_to_home)\n",
    "\n",
    "rprint(f\"[LOG] Configuration files found (x{len(input_configuration_filepaths_relative_to_home)}): '{\"' | '\".join(input_configuration_filepaths_relative_to_home)}'.\")\n",
    "rprint(f\"[LOG] User parameters files found (x{len(input_user_parameters_filepaths_relative_to_home)}): '{\"' | '\".join(input_user_parameters_filepaths_relative_to_home)}'.\")\n",
    "rprint(f\"[LOG] User files found (x{len(input_user_files_filepaths_relative_to_home)}): '{\"' | '\".join(input_user_files_filepaths_relative_to_home)}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [INITIALIZATION] INPUT: CONFIGURATION FILE(S) LOAD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0371fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load configuration YAML file.\n",
    "#  - Load '.yaml' file: 'https://www.geeksforgeeks.org/python/parse-a-yaml-file-in-python/'.\n",
    "yaml_variables_data = None\n",
    "yaml_variables_list = []\n",
    "\n",
    "for yaml_filepath in input_configuration_filepaths_relative_to_home:\n",
    "    with open(yaml_filepath, 'r') as file:\n",
    "        yaml_variables_data = yaml.load(file, Loader = yaml.SafeLoader)\n",
    "    if yaml_variables_data is not None:                              #  1st check YAML file is not empty.\n",
    "        if yaml_variables_data['parameters'] is not None:            #  2nd check if there is a 'parameters' section.\n",
    "            yaml_variables_list += yaml_variables_data['parameters']      #  Or also could use '<list>.extend(<other_list>)': 'https://sparkbyexamples.com/python/python-append-list-to-a-list/'.\n",
    "            # rprint(f\"[LOG] Variables imported (x{len(yaml_variables_data['parameters'])}), from '{yaml_filepath}'.\")\n",
    "\n",
    "rprint(f\"[LOG] Variables imported in total (x{len(yaml_variables_list)}), from: '{\"' | '\".join(input_configuration_filepaths_relative_to_home)}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40dbc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get a dictionary of variables from YAML file, with proper data conversion.\n",
    "yaml_variables_dictionary = UDFCreateVariablesDictionaryFromFormattedList(yaml_variables_list)\n",
    "\n",
    "#  Load variables YAML file into globals().\n",
    "UDFLoadVariablesToGlobals(yaml_variables_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f919c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set execution timezone.\n",
    "_TIME_ZONE = zoneinfo.ZoneInfo(_USER_GEOGRAPHIC_TIMEZONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [INITIALIZATION] INPUT: USER PARAMETERS FILE(S) LOAD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load user parameters CSV file and gets a dictionary with 1. the dataframe, and 2. list equivalent (records-like).\n",
    "user_variables_objects_dictionary   = UDFLoadCSVUserParameters(input_user_parameters_filepaths_relative_to_home[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812227a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create deepcopy of output from loading user parameters CSV.\n",
    "# user_variables_dataframe            = copy.deepcopy(user_variables_objects_dictionary['user_variables_dataframe'])\n",
    "user_variables_list                 = copy.deepcopy(user_variables_objects_dictionary['user_variables_list'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69490752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get a dictionary of variables from user configuration file, with proper data conversion.\n",
    "user_variables_dictionary = UDFCreateVariablesDictionaryFromFormattedList(user_variables_list)\n",
    "\n",
    "#  Load variables YAML file into globals().\n",
    "UDFLoadVariablesToGlobals(user_variables_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc24da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [MAIN] Load user selected song_lines file; e.g. 'song_lines-lemon_demon-fine.csv'\n",
    "\n",
    "#  Get filenames of user files, using the filepaths relative to home, previously obtained.\n",
    "#\n",
    "#  [OP01] Using list comprehension: 'https://stackoverflow.com/questions/25082410/apply-function-to-each-element-of-a-list/25082458#25082458', 'https://ellibrodepython.com/list-comprehension-python', 'https://www.geeksforgeeks.org/python/apply-function-to-each-element-of-a-list-python/'.\n",
    "input_user_files_filenames = [os.path.basename(input_user_files_filepath) for input_user_files_filepath in input_user_files_filepaths_relative_to_home]\n",
    "#  Throws an AssertionError, if no path found.\n",
    "assert user_song_lines_file in input_user_files_filenames, f\"[ERROR] Input file called '{user_song_lines_file}', provided by user in '{input_user_parameters_filepaths_relative_to_home[0]}', should exist in order for current script to run properly.\"\n",
    "#\n",
    "# #  [OP02] Using filtering with lambda functions in lists: 'https://labex.io/tutorials/python-how-to-filter-list-with-conditions-419442'.\n",
    "# input_user_files_filename_list = list(filter(\n",
    "#         lambda x : x == user_song_lines_file,\n",
    "#         map(\n",
    "#             lambda y : os.path.basename(y),     #  Or simply 'os.path.basename', without using lambda.\n",
    "#             input_user_files_filepaths_relative_to_home\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "# #  Throws an AssertionError, if no match.\n",
    "# assert len(input_user_files_filename_list) > 0, f\"[ERROR] Input file called '{user_song_lines_file}', provided by user in '{input_user_parameters_filepaths_relative_to_home[0]}', should exist in order for current script to run properly.\"\n",
    "\n",
    "#  Gets filepaths of song lines file, defined by user in variable 'user_song_lines_file'.\n",
    "song_lines_csv_filepaths = list(filter(\n",
    "        lambda x : os.path.basename(x) == user_song_lines_file,\n",
    "        input_user_files_filepaths_relative_to_home\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10395514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load song lines CSV file and gets a dictionary with 1. the dataframe, and 2. list of tuples.\n",
    "song_lines_objects_dictionary   = UDFLoadCSVSongLines(song_lines_csv_filepaths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create deepcopy of output from loading song lines CSV.\n",
    "# song_lines_dataframe            = copy.deepcopy(song_lines_objects_dictionary['song_lines_dataframe'])\n",
    "song_lines_list                 = copy.deepcopy(song_lines_objects_dictionary['song_lines_list'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [MAIN] Play song lines typewriter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a60ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Delay message popup before starting song lines typewriter.\n",
    "#  - Backwards iteration: 'https://www.geeksforgeeks.org/python/backward-iteration-in-python/', 'https://docs.python.org/3/library/functions.html#func-range'.\n",
    "for i in range(_TIME_DELAY_FOR_START_OF_SONG_LINES_TYPEWRITER, 0, -1):\n",
    "    if ((i == (_TIME_DELAY_FOR_START_OF_SONG_LINES_TYPEWRITER)) or (i == 5) or (i == 3) or (i == 2) or (i == 1)): {\n",
    "        # print(i)\n",
    "        print(f\"Song lyrics will start to roll in {i} seconds...\")\n",
    "    }\n",
    "    sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "UDFSongLinesTypewriter(song_lines_list, _INTERVAL_FOR_CLEARING_OUTPUT_AFTER_REGULAR_LINES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860526c4",
   "metadata": {},
   "source": [
    "# TODOS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e187f1a",
   "metadata": {},
   "source": [
    "## Play Song and Allow Audio through Docker Container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9513b",
   "metadata": {},
   "source": [
    "### Play Sound in Python.\n",
    "\n",
    "- URL: '<https://pythonbasics.org/python-play-sound/>'.\n",
    "- Options:\n",
    "    - Simple player: 'playsound' module.\n",
    "    - More rich feature player: 'pydub' module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1bda4",
   "metadata": {},
   "source": [
    "#### OPTION 01: 'playsound' Module.\n",
    "\n",
    "- URL: 'https://github.com/TaylorSMarks/playsound'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  PACKAGE VALIDATION.\n",
    "\n",
    "# !pip show playsound | grep Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  INSTALLATION.\n",
    "\n",
    "# !pip install --upgrade setuptools wheel #  In case 'pip install playsound' throws error 'OSError: could not get source code': 'https://stackoverflow.com/questions/76142067/on-github-actions-pip-install-playsound-failed-with-the-oserror-could-not-g/77869687#77869687', 'https://www.reddit.com/r/termux/comments/116825n/comment/jd2znkd/'.\n",
    "# !pip install pygobject # In case, when importing, shows message: 'playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.'\n",
    "# !pip install playsound\n",
    "\n",
    "# #  NOTE: throwing error, since it has not been possible to run 'pip install pygobject'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e330dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  IMPORTING.\n",
    "\n",
    "# from playsound import playsound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1dc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_dirpath = 'io_dir-input/user_files/song-lemon_demon-fine.mp3'\n",
    "# playsound(song_dirpath)\n",
    "\n",
    "# #  NOTE: throwing error, since it has not been possible to run 'pip install pygobject'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d069feb6",
   "metadata": {},
   "source": [
    "#### OPTION 02: 'pydub' Module.\n",
    "\n",
    "- URL: 'https://github.com/jiaaro/pydub'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460126e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  PACKAGE VALIDATION.\n",
    "\n",
    "# !pip show pydub | grep Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  INSTALLATION.\n",
    "\n",
    "# !pip install pydub                                  #  Installation: 'https://github.com/jiaaro/pydub?tab=readme-ov-file#installation'.\n",
    "# !sudo apt -y install ffmpeg libavcodec-extra        #  Dependencies for playback: 'https://github.com/jiaaro/pydub?tab=readme-ov-file#getting-ffmpeg-set-up'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48acb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  IMPORTING.\n",
    "\n",
    "# from pydub import AudioSegment                      #  Manipulate audio: 'https://github.com/jiaaro/pydub?tab=readme-ov-file#quickstart'.\n",
    "# from pydub.playback import play as splay            #  Playback audio: 'https://github.com/jiaaro/pydub?tab=readme-ov-file#playback'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec79b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_dirpath    = 'io_dir-input/user_files/song-lemon_demon-fine.mp3'\n",
    "# sound_to_play   = AudioSegment.from_file(song_dirpath, format = 'mp3')\n",
    "# splay(sound_to_play)\n",
    "\n",
    "# #  NOTE: throwing error, since it has no access to sound card. Review follwing links:\n",
    "# #+ - Ref. 'https://srivastavayushmaan1347.medium.com/docker-task-giving-sound-card-access-to-a-program-inside-docker-92080304de79'.\n",
    "# #+ - Ref. 'https://medium.com/@18bhavyasharma/enabling-sound-card-access-in-docker-containers-using-pulseaudio-d52ff1f5eee4'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067a81b",
   "metadata": {},
   "source": [
    "### Allow Audio through Docker Container.\n",
    "\n",
    "- URL 01: '<https://srivastavayushmaan1347.medium.com/docker-task-giving-sound-card-access-to-a-program-inside-docker-92080304de79>'.\n",
    "- URL 02: '<https://medium.com/@18bhavyasharma/enabling-sound-card-access-in-docker-containers-using-pulseaudio-d52ff1f5eee4>'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
